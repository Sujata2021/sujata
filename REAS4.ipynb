{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f591e6b-ef2a-498d-92a0-2055b25a6709",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab5363-97d9-4cd6-9593-db4c4ffca3e7",
   "metadata": {},
   "source": [
    "Lasso regression stands for Least Absolute Shrinkage and Selection Operator. It adds penalty term to the cost function. This term is the absolute sum of the coefficients. As the value of coefficients increases from 0 this term penalizes, cause model, to decrease the value of coefficients in order to reduce loss. The difference between ridge and lasso regression is that it tends to make coefficients to absolute zero as compared to Ridge which never sets the value of coefficient to absolute zero.\n",
    "\n",
    "Sometimes, the lasso regression can cause a small bias in the model where the prediction is too dependent upon a particular variable. In these cases, elastic Net is proved to better it combines the regularization of both lasso and Ridge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84367fe1-32d5-46b4-b39a-813b2e515c73",
   "metadata": {},
   "source": [
    "### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010f19-1e38-455e-852c-9f6751b1b859",
   "metadata": {},
   "source": [
    "The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdbf497-9900-41cf-b71b-4099755296d6",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6521d-21c9-461d-bb0f-55d54e23cbee",
   "metadata": {},
   "source": [
    "In Lasso regression, some of the coefficients will be set to zero, which means that the corresponding feature has been excluded from the model. The non-zero coefficients represent the features that are most important for predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c803f-3979-42b2-87e6-56f79a90fc4d",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364bffca-a2b5-44ad-8e9f-87cce92ff6b7",
   "metadata": {},
   "source": [
    "A tuning parameter (λ), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean. Shrinkage results in simple, sparse models which are easier to analyze than high-dimensional data models with large numbers of parameters.\n",
    "\n",
    "When λ = 0, no parameters are eliminated. The estimate is equal to the one found with linear regression.\n",
    "\n",
    "As λ increases, more and more coefficients are set to zero and eliminated.\n",
    "When λ = ∞, all coefficients are eliminated.\n",
    "\n",
    "There is a trade-off between bias and variance in resulting estimators. As λ increases, bias increases and as λ decreases, variance increases. For example, setting your tuning parameter to a low value results in a more manageable number of model parameters and lower bias, but at the expense of a much larger variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89d3c4-b46c-4a5a-a197-2e96b1d5faf2",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31593dc6-3a28-462e-befc-1b562d3ed30c",
   "metadata": {},
   "source": [
    "In general lasso regression cann't be used for non-linear regression problems.If we can linearize the model, then yes but for an approximate solution in the LS sense since what is measured is y and not any of its possible transforms. If model is nonlinear because of one parameter, there are things which can be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910a578-31a3-4329-8bf8-2c980088d6ce",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f697b-31dd-44a6-ba03-b77ca32249b0",
   "metadata": {},
   "source": [
    "The difference between ridge and lasso regression is that it tends to make coefficients to absolute zero as compared to Ridge which never sets the value of coefficient to absolute zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cef08-acf9-4820-aa30-0eb3ffc07501",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e2434-aa7c-4427-8e51-5d2363f3fd77",
   "metadata": {},
   "source": [
    "If there are two or more highly collinear variables then LASSO regression select one of them randomly which is not good for the interpretation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a4067-5e0b-45b5-995b-1266e0a42bf0",
   "metadata": {},
   "source": [
    "To reduce multicollinearity we can use regularization that means to keep all the features but reducing the magnitude of the coefficients of the model. This is a good solution when each predictor contributes to predict the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7956d-445d-4ac4-977f-f455ad9a322d",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c5cda-d8b2-4888-b772-11b9e31f298c",
   "metadata": {},
   "source": [
    " Lambda is a positive value and can range from 0 to positive infinity. But typically chosen to be between 0 and 10.\n",
    "\n",
    "So, how do we choose the penalty value lambda? The answer is Cross-Validation.\n",
    "\n",
    "Cross-validation is a way to tune the hyperparameters using only the training data. There are different variations of cross-validation, but the most common one is 10-Fold Cross-Validation.\n",
    "\n",
    "Remember, data is a limited resource and we have to use it wisely. The main thing to remember here is that we have to keep the test data away from the algorithm and do all the validation only on the training data.\n",
    "\n",
    "Step 1: First split the entire dataset into training and testing sets. (70%-30% or 80%-20%).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3417cb-42e7-43a3-b425-0987732c17fd",
   "metadata": {},
   "source": [
    "Step 2: Now keeping the test set away, split the training data into 10 equal folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393da929-b10a-4d85-9d11-4618e2532b8b",
   "metadata": {},
   "source": [
    "Step 3: Now say we choose lambda = 0.2. Train the model on 9 of the folds and evaluate the model on the holdout fold (which now acts as testing data within the training data) and get the holdout score, which is the performance score of that model. Say we get 0.52\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b6803-3f13-467d-acd2-e526db6e88a6",
   "metadata": {},
   "source": [
    "Step 4: Repeat step 3 for 9 times, each time on a different holdout fold, and record their holdout scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cca92-55fe-4dc1-9532-543d882c03c9",
   "metadata": {},
   "source": [
    "Step 5: After all the iterations are done, the model would have been trained each time using different folds on 10 different hold-out folds giving 10 different holdout scores. To get the final Cross-Validation score take the average of all the individual holdout scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49203f91-8479-43ad-93c5-287a54c00051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
