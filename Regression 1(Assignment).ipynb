{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8dc43d4-15d1-4f59-9db3-67e2bcd32ea6",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb38ce-91a0-409d-bead-7900773446c0",
   "metadata": {},
   "source": [
    "In simple linear regression, there is only one independent variable (predictor variable) used to predict the dependent variable.In multiple linear regression, there are two or more independent variables used to predict the dependent variable. It extends the concept of simple linear regression to accommodate multiple predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844865ac-03ac-4ce1-99ae-ede1542c9765",
   "metadata": {},
   "source": [
    "The relationship between the independent and dependent variables is modeled as a straight line. The goal is to find the best-fitting line that minimizes the sum of squared differences between the observed and predicted values.The relationship between the dependent and independent variables is modeled as a hyperplane (a higher-dimensional analog of a plane) in a space with dimensions equal to the number of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ec50e-7af3-4613-a95a-f6cb1a2b5444",
   "metadata": {},
   "source": [
    "For instance, when we predict rent based on square feet alone that is simple linear regression.\n",
    "\n",
    "When we predict rent based on square feet and age of the building that is an example of multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1965fa-7699-44a4-85b3-b542e5642bb6",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c6223-3984-43b1-b514-aea5dbe8c18c",
   "metadata": {},
   "source": [
    "Linearity: The relationship between the dependent and independent variables is linear.\n",
    "\n",
    "Independence: The observations are independent of each other.\n",
    "\n",
    "Homoscedasticity: The variance of the errors is constant across all levels of the independent variables.\n",
    "\n",
    "Normality: The errors follow a normal distribution.\n",
    "\n",
    "No multicollinearity: The independent variables are not highly correlated with each other.\n",
    "\n",
    "No endogeneity: There is no relationship between the errors and the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea6092-b160-44aa-b94c-b3a86083f253",
   "metadata": {},
   "source": [
    "This assumption can best be checked with a histogram or a Q-Q-Plot.  Normality can be checked with a goodness of fit test, e.g., the Kolmogorov-Smirnov test.  When the data is not normally distributed a non-linear transformation (e.g., log-transformation) might fix this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68440d-f580-4c2d-b9ce-09647d18c59e",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5ccfc-70fe-4703-9515-fd8a94cdb06d",
   "metadata": {},
   "source": [
    "When modeling linear data, the slope and intercept of the graph provide useful information about the initial conditions and rate of change of what is being studied. First, the slope of a line is a measure of its steepness. In a line, slope is a ratio of the change in one variable to the change in the other. Usually, this refers to the change in y for each unit change in x, but sometimes other variables may be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c4923-a986-40d6-aa5f-9f3de113d752",
   "metadata": {},
   "source": [
    "The intercept refers to the y-intercept, which is where the line intersects the y-axis. Again, other variables may be used, but the intercept generally refers to the independent variable and the vertical axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa5c90e-7d1e-4d44-b556-4ac49d94d52b",
   "metadata": {},
   "source": [
    "If the speed of the club hitting the ball increases by 1 mph, then the model predicts that the length the ball travels increases by 57.66 yards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aebc38-0174-48cb-949a-bd84155bf5e2",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d90028-14fb-4c6f-aa98-c93d56f6f6d4",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba657c-604d-4e89-a79d-572c8d1d32a2",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03048803-9722-4011-8ea0-73dd9fc14bd0",
   "metadata": {},
   "source": [
    "Multiple Regression\n",
    "For complex connections between data, the relationship might be explained by more than one variable. In this case, an analyst uses multiple regression which attempts to explain a dependent variable using more than one independent variable.\n",
    "\n",
    "There are two main uses for multiple regression analysis. The first is to determine the dependent variable based on multiple independent variables. For example, you may be interested in determining what a crop yield will be based on temperature, rainfall, and other independent variables. The second is to determine how strong the relationship is between each variable. For example, you may be interested in knowing how a crop yield will change if rainfall increases or the temperature decreases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d9ce7-8a0b-4bd1-a65b-b6f8f130d6d2",
   "metadata": {},
   "source": [
    "linear regress only has one independent variable impacting the slope of the relationship, multiple regression incorporates multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf586b5b-3c19-4c3b-a6a3-c983d5dab356",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c8d96-18e3-4b28-977c-2ef7d978740b",
   "metadata": {},
   "source": [
    "Multicollinearity refers to the statistical phenomenon where two or more independent variables are strongly correlated. It marks the almost perfect or exact relationship between the predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e65d4-1098-4a91-aca2-8d3e1b84a318",
   "metadata": {},
   "source": [
    "There are two simple ways to indicate multicollinearity in the dataset on EDA or obtain steps using Python.\n",
    "\n",
    "Variance Inflation Factor (VIF).\n",
    "\n",
    "Heat map or correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300ad14-0997-4227-be13-88f9d59ec9d2",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90892805-5419-440b-9146-4a33c1017610",
   "metadata": {},
   "source": [
    "A polynomial regression model is a machine learning model that can capture non-linear relationships between variables by fitting a non-linear regression line, which may not be possible with simple linear regression. It is used when linear regression models may not adequately capture the complexity of the relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b1934-4ba8-4ef0-b089-55972ef3eaa9",
   "metadata": {},
   "source": [
    "Polynomial regression, denoted as E(y | x), characterizes fitting a nonlinear relationship between the x value and the conditional mean of y. Typically, this corresponds to the least-squares method. The least-square approach minimizes the coefficient variance according to the Gauss-Markov Theorem. This represents a type of Linear Regression where the dependent and independent variables exhibit a curvilinear relationship and the polynomial equation is fitted to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb48b1-2b46-4bed-89c9-c0e6cf53a8d5",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f5501-8a56-40d9-a17c-17d2c424d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVANTAGES:-\n",
    "\n",
    "1.Works on any size of the databases.\n",
    "\n",
    "2.Works very well on non-linear problems.\n",
    "\n",
    "DISAVANTAGES:-\n",
    "\n",
    "1.We need to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61263703-838e-460a-8b55-457b9d37fbc3",
   "metadata": {},
   "source": [
    "Rather than focusing on the distinctions between linear and polynomial regression, we may comprehend the importance of polynomial regression by starting with linear regression. We build our model and realize that it performs abysmally. We examine the difference between the actual value and the best fit line we predicted, and it appears that the true value has a curve on the graph, but our line is nowhere near cutting the mean of the points. This is where polynomial regression comes into play; it predicts the best-fit line that matches the pattern of the data (curve).\n",
    "\n",
    "One important distinction between Linear and Polynomial Regression is that Polynomial Regression does not require a linear relationship between the independent and dependent variables in the data set. When the Linear Regression Model fails to capture the points in the data and the Linear Regression fails to adequately represent the optimum, then we use Polynomial Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ac569-782c-4870-be28-f7e7ed3cc01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
