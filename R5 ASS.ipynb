{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff284b5d-deb1-4363-9895-4de6e2fc15d7",
   "metadata": {},
   "source": [
    "## Q1. What is Elastic Net Regression and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f1812-b01d-4c53-b32d-e53bc07c6b00",
   "metadata": {},
   "source": [
    "Elastic net regression is a linear regression technique that uses a penalty term to shrink the coefficients of the predictors. The penalty term is a combination of the l1-norm (absolute value) and the l2-norm (square) of the coefficients, weighted by a parameter called alpha. The l1-norm penalty is similar to lasso, which tends to produce sparse solutions by setting some coefficients to zero. The l2-norm penalty is similar to ridge, which tends to reduce the variance of the coefficients by shrinking them towards zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d4d750-06ab-4361-91d6-590dc65e68e8",
   "metadata": {},
   "source": [
    "The main difference between elastic net and lasso or ridge is that elastic net has an additional parameter called lambda, which controls the balance between the l1-norm and the l2-norm penalties. When lambda is zero, elastic net is equivalent to lasso. When lambda is one, elastic net is equivalent to ridge. When lambda is between zero and one, elastic net is a compromise between lasso and ridge. This allows elastic net to adapt to different situations and data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b26604-f0ab-4df2-8557-386965351872",
   "metadata": {},
   "source": [
    "## Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80629f3b-bded-4283-9152-b459046eecd8",
   "metadata": {},
   "source": [
    "The regularization parameters for the implementation of Elastic Net Regression are:\n",
    "\n",
    "λ ,and\n",
    "L1 ratio\n",
    "where, λ = λ(Ridge) + λ(Lasso) and is written as:\n",
    "\n",
    "L1_ratio\n",
    "The formula for L1_ratio for all the methods becomes:\n",
    "\n",
    " Regularization Technique\tPenalty\n",
    "    \n",
    "L1_ratio = 0\tRidge Regression\tL-2\n",
    "\n",
    "L1_ratio = 1\tLasso Regression\tL-1\n",
    "\n",
    "0< L1_ratio <1\tElastic Net Regression\tCombination of L-1 and L-2\n",
    "\n",
    "In Python, the strength of the penalty is controlled by the argument called alpha. If:\n",
    "\n",
    "alpha = 0, then will become Ridge, and\n",
    "alpha = 1, then it becomes Lasso.\n",
    "\n",
    "The Elastic Net Regression happens in two stages:\n",
    "\n",
    "the first stage is Ridge Regression, and\n",
    "then the second stage is the LASSO Regression.\n",
    "\n",
    "In each stage, the betas get reduced or shrunken, resulting in an increased bias in the model. An increase in bias means a lot of deviation between the predicted values and the actual values and therefore makes more predictions. Hence, we rescale the coefficients of Elastic Net Regularization by multiplying the estimated coefficients by (1+λridge) to improve the prediction performance and decrease the bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb92511-d347-492f-9426-39986144c7f3",
   "metadata": {},
   "source": [
    "## Q3. What are the advantages and disadvantages of Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a69a19-71b6-41c0-8d41-dec781bed2c6",
   "metadata": {},
   "source": [
    "One of the benefits of elastic net is that it can handle multicollinearity, which is when some predictors are highly correlated with each other. Lasso can suffer from instability and inconsistency when there is multicollinearity, as it may arbitrarily select one predictor over another. \n",
    "\n",
    "Another benefit of elastic net is that it can reduce overfitting, which is when the model fits the training data too well, but performs poorly on new or unseen data. \n",
    "\n",
    "A third benefit of elastic net is that it can perform feature selection, which is when the model identifies the most important predictors for the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797f9d6-a99f-4746-92f6-db27a91942ba",
   "metadata": {},
   "source": [
    "One of the pitfalls and challenges of elastic net is that it requires tuning two hyperparameters: alpha and lambda. Hyperparameters are parameters that are not learned by the model, but need to be specified by the user. Tuning hyperparameters means finding the optimal values that minimize the error or maximize the performance of the model. Tuning hyperparameters can be time-consuming and computationally expensive, as it requires testing different combinations of values and evaluating their results.\n",
    "\n",
    "\n",
    "Another pitfall and challenge of elastic net is that it may not work well for some types of data or problems. For example, elastic net may not be suitable for high-dimensional data, where the number of predictors is much larger than the number of observations. In this case, elastic net may not be able to select the relevant features or reduce the dimensionality effectively. Elastic net may also not be suitable for non-linear problems, where the relationship between the predictors and the outcome is not linear. In this case, elastic net may not be able to capture the complexity or the interactions of the data.\n",
    "\n",
    "A third pitfall and challenge of elastic net is that it may not be interpretable or explainable. Interpretability and explainability are the ability to understand how the model works and why it makes certain predictions. Lasso and ridge are relatively simple and intuitive, as they have a clear relationship between the coefficients and the predictors. Elastic net is more complex and ambiguous, as it involves a combination of two penalties and two hyperparameters. Elastic net may not provide a clear or meaningful explanation of the model or its results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acd3e1-39ac-4f34-a31b-76805d1e4548",
   "metadata": {},
   "source": [
    "## Q4. What are some common use cases for Elastic Net Regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d4558-148e-4bfa-a549-2082350796a2",
   "metadata": {},
   "source": [
    "Metric learning\n",
    "\n",
    "Portfolio optimization\n",
    "\n",
    "Cancer prognosis\n",
    "\n",
    "ElasticNet Regression finds applications in various domains, including finance, healthcare, genetics, and social sciences. It is used for predicting stock prices, analyzing medical data, identifying genetic markers, and understanding social phenomena, among other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3515dea-36b1-45ea-9a5c-fc8145fcb5b8",
   "metadata": {},
   "source": [
    "## Q5. How do you interpret the coefficients in Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8a962-dc7e-47ff-b041-f500fa1f3e2f",
   "metadata": {},
   "source": [
    "The coefficients of elastic net regression represent the linear relationship between the features and the target variable, adjusted by the regularization terms. The larger the absolute value of a coefficient, the stronger the effect of the corresponding feature on the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5b5f4-124f-4733-a951-975ad6ec5303",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values when using Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddf885-0d37-49a2-99a6-4b26562a98db",
   "metadata": {},
   "source": [
    "Handling missing values: Address any missing values in your dataset before applying ElasticNet Regression. Depending on the extent and nature of the missing data, we can choose to impute missing values or remove the corresponding observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d615b65-2955-49ce-b4d0-71c23d94a792",
   "metadata": {},
   "source": [
    "## Q7. How do you use Elastic Net Regression for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764b667-9aa5-49eb-be9d-185ca17f9e03",
   "metadata": {},
   "source": [
    "One of the major advantages of ElasticNet Regression is its ability to perform feature selection. By applying the L1 penalty, ElasticNet Regression encourages sparsity, effectively setting some coefficients to zero and selecting the most relevant features for the model. This can simplify the model, improve interpretability, and reduce overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecff7f-2074-45ea-aff9-2720636f1921",
   "metadata": {},
   "source": [
    "## Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7d970-a283-4956-923b-52c1d9d75465",
   "metadata": {},
   "source": [
    "Using pickle , simply save your model on disc with dump() function and de-pickle it into your python code with load() function. Use open() function to create and/or read from a . pkl file and make sure you open the file in the binary format by wb for write and rb for read mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377a652-61d3-448d-a7b5-73902d406cac",
   "metadata": {},
   "source": [
    "## Q9. What is the purpose of pickling a model in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48738a3-30ca-42dd-907c-d01cd0f8067f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
