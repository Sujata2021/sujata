{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce219960-fc0b-40a7-802d-11918ead408f",
   "metadata": {},
   "source": [
    "### Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae41635-e935-4a5c-8cdd-8ff781647974",
   "metadata": {},
   "source": [
    "A statistical model is said to be overfitted when the model does not make accurate predictions on testing data. When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set. And when testing with test data results in High variance.\n",
    "\n",
    "A solution to avoid overfitting is using a linear algorithm if we have linear data or using the parameters like the maximal depth if we are using decision trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2c3ec-d2d6-4ba8-b2b6-44427d3604ca",
   "metadata": {},
   "source": [
    "A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on training data but performs poorly on testing data.High bias and low variance.\n",
    "\n",
    "ncrease model complexity.\n",
    "\n",
    "Increase the number of features, performing feature engineering.\n",
    "\n",
    "Remove noise from the data.\n",
    "\n",
    "Increase the number of epochs or increase the duration of training to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9ac69-bc03-403e-bae2-808bdd9f7b9f",
   "metadata": {},
   "source": [
    "### Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da93c8-e6c9-4da6-9d0e-b17316ca2124",
   "metadata": {},
   "source": [
    "Increase training data.\n",
    "\n",
    "Reduce model complexity.\n",
    "\n",
    "Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "\n",
    "Ridge Regularization and Lasso Regularization.\n",
    "\n",
    "Use dropout for neural networks to tackle overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae30327-96b9-49cf-889d-16041ee2b3af",
   "metadata": {},
   "source": [
    "### Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaebe94-d7f5-4844-9848-74cf8ccbc0d3",
   "metadata": {},
   "source": [
    "A statistical model or a machine learning algorithm is said to have underfitting when it\n",
    "\n",
    "cannot capture the underlying trend of the data, i.e., it only performs well on training\n",
    "\n",
    "data but performs poorly on testing data. (It’s just like trying to fit undersized\n",
    "\n",
    "pants!) Underfitting destroys the accuracy of our machine-learning model. Its occurrence\n",
    "\n",
    "simply means that our model or the algorithm does not fit the data well enough. It\n",
    "\n",
    "usually happens when we have less data to build an accurate model and also when we try to\n",
    "\n",
    "build a linear model with fewer non-linear data. In such cases, the rules of the machine\n",
    "\n",
    "learning model are too easy and flexible to be applied to such minimal data, and\n",
    "\n",
    "therefore the model will probably make a lot of wrong predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950f31f-ace0-4089-965d-d66014c53192",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee048e4-a9cd-4b68-8984-96645165d9b1",
   "metadata": {},
   "source": [
    "***Bias : Assumptions made by a model to make a function easier to learn. It is actually the error rate of the training data. When the error rate has a high value, we call it High Bias and when the error rate has a low value, we call it low Bias.\n",
    "\n",
    "***Variance: The difference between the error rate of training data and testing data is\n",
    "called variance. If the difference is high then it’s called high variance and when the\n",
    "difference in errors is low then it’s called low variance. Usually, we want to make a low\n",
    "variance for generalized our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3910c27-be0b-4696-b6d5-ebafebd3e1ba",
   "metadata": {},
   "source": [
    "High bias and low variance result in underfitting.\n",
    "\n",
    "low bias and high variance result in overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fbe79-2ea4-4187-8a2d-e0ef23c3a89d",
   "metadata": {},
   "source": [
    "### Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6dd5c-b7f7-4573-acd5-151589860233",
   "metadata": {},
   "source": [
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2688c92-d001-46c0-9832-cda4f003e367",
   "metadata": {},
   "source": [
    "Reasons for Overfitting:\n",
    "\n",
    " High variance and low bias.\n",
    " \n",
    "The model is too complex.\n",
    "\n",
    "The size of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511ca28-5e03-4807-853d-3aeee68e07b3",
   "metadata": {},
   "source": [
    "Reasons for Underfitting\n",
    "\n",
    "High bias and low variance.\n",
    "\n",
    "The size of the training dataset used is not enough.\n",
    "\n",
    "The model is too simple.\n",
    "\n",
    "Training data is not cleaned and also contains noise in it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa844d-d121-42c9-9f48-2e23f8226e19",
   "metadata": {},
   "source": [
    "### Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9619d-18a7-4233-95e8-ac66cc9cbeca",
   "metadata": {},
   "source": [
    "Bias is one type of error that occurs due to wrong assumptions about data such as assuming data is linear when in reality, data follows a complex function. On the other hand, variance gets introduced with high sensitivity to variations in training data. This also is one type of error since we want to make our model robust against noise. There are two types of error in machine learning. Reducible error and Irreducible error. Bias and Variance come under reducible error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d1b7b-43c8-4b7f-881e-61b004cd0d3a",
   "metadata": {},
   "source": [
    "High Bias: High bias value means more assumptions are taken to build the target function. In this case, the model will not match the training dataset closely. \n",
    "The high-bias model will not be able to capture the dataset trend. It is considered as the underfitting model which has a high error rate. It is due to a very simplified algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484cf8ff-4895-44cc-8d0f-4335e775ce2a",
   "metadata": {},
   "source": [
    "High variance: High variance means that the model is very sensitive to changes in the training data and can result in significant changes in the estimate of the target function when trained on different subsets of data from the same distribution. This is the case of overfitting when the model performs well on the training data but poorly on new, unseen test data. It fits the training data too closely that it fails on the new training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631703a1-6497-4128-aa6f-9fdd685cdbc2",
   "metadata": {},
   "source": [
    "### Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112e4ea-33e6-4252-951f-8b2e9a5a48eb",
   "metadata": {},
   "source": [
    "Regularization is a technique used to reduce errors by fitting the function appropriately on the given training set and avoiding overfitting. The commonly used regularization techniques are : \n",
    "\n",
    "Lasso Regularization – L1 Regularization\n",
    "\n",
    "Ridge Regularization – L2 Regularization\n",
    "\n",
    "Elastic Net Regularization – L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5726925-6628-4ad6-812f-6c1f07709200",
   "metadata": {},
   "source": [
    "***Lasso Regression\n",
    "\n",
    "A regression model which uses the L1 Regularization technique is called LASSO(Least Absolute Shrinkage and Selection Operator) regression. Lasso Regression adds the “absolute value of magnitude” of the coefficient as a penalty term to the loss function(L). Lasso regression also helps us achieve feature selection by penalizing the weights to approximately equal to zero if that feature does not serve any purpose in the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***Ridge Regression\n",
    "\n",
    "A regression model that uses the L2 regularization technique is called Ridge regression. Ridge regression adds the “squared magnitude” of the coefficient as a penalty term to the loss function(L).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***Elastic Net Regression\n",
    "\n",
    "This model is a combination of L1 as well as L2 regularization. That implies that we add the absolute norm of the weights as well as the squared measure of the weights. With the help of an extra hyperparameter that controls the ratio of the L1 and L2 regularization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c57026-2551-40e2-bb72-a1917ea89c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
