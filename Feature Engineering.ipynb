{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcc8d68-f6fc-4c64-a3bf-861528c7ba23",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20b709-1a2d-4591-bff8-dc796ba21c8e",
   "metadata": {},
   "source": [
    "Missing data, or missing values, occur when you don’t have data stored for certain variables or participants. Data can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db215678-971b-414a-8707-2a6aa3679175",
   "metadata": {},
   "source": [
    "Missing data are problematic because, depending on the type, they can sometimes cause sampling bias. This means your results may not be generalizable outside of your study because your data come from an unrepresentative sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f6a92-2378-46af-985b-01be5659cbda",
   "metadata": {},
   "source": [
    "1.k-NN\n",
    "\n",
    "2.Random Forest algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc88b9-baf3-43b2-b563-0f27eddeaaf5",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329995d4-ae01-4569-89a8-3bedd806158e",
   "metadata": {},
   "source": [
    ".isnull()\n",
    "\n",
    "This function returns a pandas dataframe, where each value is a boolean value True if the value is missing, False otherwise.\n",
    "\n",
    ".notnull()\n",
    "\n",
    "Similarly to the previous function, the values for this one are False if either NaN or None value is detected.\n",
    "\n",
    ".info()\n",
    "\n",
    "This function generates three main columns, including the “Non-Null Count” which shows the number of non-missing values for each column.\n",
    "\n",
    ".isna()\n",
    "\n",
    "This one is similar to isnull and notnull. However it shows True only when the missing value is NaN type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343f5b89-9ca1-43cf-8f9c-1ae7012cf9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset(\"titanic\")\n",
    "df.head()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee843e9b-d7a3-4973-8a2d-f855fb22adff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       891\n",
       "pclass         891\n",
       "sex            891\n",
       "age            714\n",
       "sibsp          891\n",
       "parch          891\n",
       "fare           891\n",
       "embarked       889\n",
       "class          891\n",
       "who            891\n",
       "adult_male     891\n",
       "deck           203\n",
       "embark_town    889\n",
       "alive          891\n",
       "alone          891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e512bea5-b150-4a9a-88b3-2ba0c44232ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea8545f-974d-4f3b-8ba8-7f845806730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb0c36-6b23-4d6a-983f-7ddc34a97e8b",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8bec4-ed74-42c4-9a89-a408cb9f2704",
   "metadata": {},
   "source": [
    "A classification data set with skewed class proportions is called imbalanced. Classes that make up a large proportion of the data set are called majority classes. Those that make up a smaller proportion are minority classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc230dc4-25a4-48db-9bb4-c4666c013b19",
   "metadata": {},
   "source": [
    "Data fuels machine learning algorithms. In the absence of a good quality dataset, even the best of algorithms struggles to produce good results. An imbalanced dataset is defined by great differences in the distribution of the classes in the dataset.\n",
    "\n",
    "This means that a dataset is biased towards a class in the dataset. If the dataset is biased towards one class, an algorithm trained on the same data will be biased towards the same class.\n",
    "\n",
    "The model learns more from biased examples as opposed to the examples in the minority class. One might end up with a scenario where a model assumes that any data you feed it belongs to the majority class.\n",
    "\n",
    "This, as a result, makes a model seem naïve in its predictions, regardless of achieving high accuracy scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648fe47-135a-4db4-94f0-e34bb802920f",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35ed08-d0b8-4b6b-875e-096e76695ea1",
   "metadata": {},
   "source": [
    "Downsampling refers to removing records from majority classes in order to create a more balanced dataset. The simplest way of downsampling majority classes is by randomly removing records from that category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596890e-e2dd-4afb-9acf-e44ccf719770",
   "metadata": {},
   "source": [
    "Upsampling refers to manually adding data samples to the minority classes in order to create a more balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86745a11-07b2-46f1-b001-d9fea68bad7f",
   "metadata": {},
   "source": [
    "Instances of fraud happen once per 200 transactions in this data set, so in the true distribution, about 0.5% of the data is positive.\n",
    "\n",
    " With so few positives relative to negatives, the training model will spend most of its time on negative examples and not learn enough from positive ones. For example, if your batch size is 128, many batches will have no positive examples, so the gradients will be less informative.\n",
    "\n",
    "If you have an imbalanced data set, first try training on the true distribution.\n",
    "\n",
    "Consider again our example of the fraud data set, with 1 positive to 200 negatives. Downsampling by a factor of 10 improves the balance to 1 positive to 20 negatives (5%). Although the resulting training set is still moderately imbalanced, the proportion of positives to negatives is much better than the original extremely imbalanced proportion (0.5%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683c986-e993-4560-a1a3-0a48f01de7ff",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c19aba-df1e-4e34-8055-1a9b54c203f1",
   "metadata": {},
   "source": [
    "SMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem.\n",
    "It aims to balance class distribution by randomly increasing minority class examples by replicating them.\n",
    "SMOTE synthesises new minority instances between existing minority instances. It generates the virtual training records by linear interpolation for the minority class. These synthetic training records are generated by randomly selecting one or more of the k-nearest neighbors for each example in the minority class. After the oversampling process, the data is reconstructed and several classification models can be applied for the processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c73637-a5cb-400a-8d69-ec7bca78e1a0",
   "metadata": {},
   "source": [
    "Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b8fda-a4f4-4670-aab7-f25037607f89",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f01ed-1bb7-4516-9eec-f6bd0f11092c",
   "metadata": {},
   "source": [
    "Outlier is a data object that deviates significantly from the rest of the data objects and behaves in a different  manner. An outlier is an object that deviates significantly from the rest of the objects. They can be caused by measurement or execution errors. The analysis of outlier data is referred to as outlier analysis or outlier mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b3623-1f90-4381-a945-abdeed586690",
   "metadata": {},
   "source": [
    "Outliers can affect the accuracy, validity, and reliability of your research results, so you need to handle them carefully and appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233dcd3-f6c7-4c64-ab45-8d067fbe3995",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a01593-89a2-4f38-9b1a-d63522b1ccf4",
   "metadata": {},
   "source": [
    "Deleting Rows with missing values\n",
    "\n",
    "Impute missing values for continuous variable\n",
    "\n",
    "Impute missing values for categorical variable\n",
    "\n",
    "Other Imputation Methods\n",
    "\n",
    "Using Algorithms that support missing values\n",
    "\n",
    "Prediction of missing values\n",
    "\n",
    "Imputation using Deep Learning Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a2d98-db9c-4a5d-94a2-78e874e6667c",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa5db9-a0f1-4714-a0da-c3fe80e05b19",
   "metadata": {},
   "source": [
    "****Prior knowledge of an ideal number\n",
    "This method entails replacing the missing value with a specific value. To use it, you need to have domain knowledge of the dataset. We use this to populate the MAR and MCAR values.To implement it in Python, you use the .fillna method in Pandas.\n",
    "\n",
    "****Regression imputation\n",
    "The regression imputation method includes creating a model to predict the observed value of a variable based on another variable. Then you use the model to fill in the missing value of that variable.\n",
    "\n",
    "****Simple Imputation\n",
    "This method involves utilizing a numerical summary of the variable where the missing value occurred (that is using the feature or variable's central tendency summary, such as mean, median, and mode).\n",
    "\n",
    "****KNN Imputation\n",
    "KNN imputation is a fairer approach to the Simple Imputation method. It operates by replacing missing data with the average mean of the neighbors nearest to it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80724625-b060-4513-8f73-e335f1638111",
   "metadata": {},
   "source": [
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1576d1-608b-46ba-994a-c312d0fb6e44",
   "metadata": {},
   "source": [
    "1.Classification- Categorical values\n",
    "\n",
    "a) upsampling\n",
    "\n",
    "b)downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160b80f-f498-4457-afa7-6e3e015ba1a3",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied.What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1bb34a-9375-470c-9da2-38414d0ac436",
   "metadata": {},
   "source": [
    "Down Sampling :\n",
    "In this technique, we reduce the sample size of Majority class(customers being satisfied) and try to match it with the sample size of Minority Class(customers being dissatisfied).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e02575-05e9-45a8-8d5a-7d51a85e2239",
   "metadata": {},
   "source": [
    "Using Tree Based Models \n",
    "\n",
    "Using Anomaly Detection Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ebefa-a19a-48e6-9f63-b700610889c7",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c8532-889f-4f3b-bae8-2d1aebd90829",
   "metadata": {},
   "source": [
    "By applying Synthetic Minority Oversampling Technique(SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0ec73-9860-4e20-9bf3-a764e93b8eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
