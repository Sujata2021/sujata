{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0dadac-3daa-40b5-a6f1-0c24421cf09d",
   "metadata": {},
   "source": [
    "### Q1. What is the Filter method in feature selection, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617875f-3c43-4567-904a-b723caa78eab",
   "metadata": {},
   "source": [
    "***Filter Methods\n",
    "\n",
    "These methods are generally used while doing the pre-processing step. These methods select features from the dataset irrespective of the use of any machine learning algorithm. In terms of computation, they are very fast and inexpensive and are very good for removing duplicated, correlated, redundant features but these methods do not remove multicollinearity. Selection of feature is evaluated individually which can sometimes help when features are in isolation (don’t have a dependency on other features) but will lag when a combination of features can lead to increase in the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649a9e9-8b95-4d45-ae57-fcd9f06226b5",
   "metadata": {},
   "source": [
    "### Q2. How does the Wrapper method differ from the Filter method in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1bf12f-eeaa-4000-ab64-ad00f385b80d",
   "metadata": {},
   "source": [
    "***Wrapper methods:\n",
    "\n",
    "Wrapper methods, also referred to as greedy algorithms train the algorithm by using a subset of features in an iterative manner. Based on the conclusions made from training in prior to the model, addition and removal of features takes place. Stopping criteria for selecting the best subset are usually pre-defined by the person training the model such as when the performance of the model decreases or a specific number of features has been achieved. The main advantage of wrapper methods over the filter methods is that they provide an optimal set of features for training the model, thus resulting in better accuracy than the filter methods but are computationally more expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10d371-8ca1-4e12-a70e-00399ff17cb9",
   "metadata": {},
   "source": [
    "## Q3. What are some common techniques used in Embedded feature selection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f367739-f705-4ed3-b67b-067a7cce788f",
   "metadata": {},
   "source": [
    "***Some techniques used are:\n",
    "\n",
    "**Regularization – This method adds a penalty to different parameters of the machine learning model to avoid over-fitting of the model. This approach of feature selection uses Lasso (L1 regularization) and Elastic nets (L1 and L2 regularization). The penalty is applied over the coefficients, thus bringing down some coefficients to zero. The features having zero coefficient can be removed from the dataset.\n",
    "\n",
    "**Tree-based methods – These methods such as Random Forest, Gradient Boosting provides us feature importance as a way to select features as well. Feature importance tells us which features are more important in making an impact on the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38950b0b-8269-4e51-8b13-3cbe94fae4af",
   "metadata": {},
   "source": [
    "## Q4. What are some drawbacks of using the Filter method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cdca5-ca38-4401-a542-5dcc46d613c4",
   "metadata": {},
   "source": [
    "**Do not remove multicollinearity\n",
    "\n",
    "***Sometimes may fail in selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe71bf-2a16-40d3-897e-8333464e2778",
   "metadata": {},
   "source": [
    "## Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3b0f5-121e-466a-9bcf-f15f553cebe2",
   "metadata": {},
   "source": [
    "Filter methods are much faster compared to wrapper methods as they do not involve training the models. On the other hand, wrapper methods are computationally very expensive as well. Filter methods use statistical methods for evaluation of a subset of features while wrapper methods use cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99555f7c-8cc3-4232-8915-2f9f2c156e14",
   "metadata": {},
   "source": [
    "## Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa29cfc-08ea-4982-a38a-a38fb4b763e8",
   "metadata": {},
   "source": [
    "Information Gain\n",
    "\n",
    "Chi-square test \n",
    "\n",
    "Fisher’s Score \n",
    "\n",
    "Correlation Coefficient \n",
    "\n",
    "Variance Threshold\n",
    "\n",
    "Mean Absolute Difference (MAD)\n",
    "\n",
    "Dispersion Ratio\n",
    "\n",
    "Mutual Dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33a9c4-8582-4c45-9084-0af4f388e1a5",
   "metadata": {},
   "source": [
    "Q7. You are working on a project to predict the outcome of a soccer match. You have large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ed50d-6682-43aa-bbf4-327f2a612b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
